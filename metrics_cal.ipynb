import re
import numpy as np
import pandas as pd
from typing import Dict, Tuple


def parse_metrics_table(text: str) -> Dict[str, Tuple[float, float, float]]:
    """

    ClassID      Recall    Precision    AP@0.5
    ---------  --------  -----------  --------
    MTL            0.37         0.40      0.22
    ...
    """
    metrics = {}


    lines = text.strip().split('\n')


    for line in lines:
        line = line.strip()
        if not line or '---' in line or 'ClassID' in line:
            continue


        parts = re.split(r'\s+', line)
        if len(parts) >= 4:
            class_id = parts[0]
            try:
                recall = float(parts[1])
                precision = float(parts[2])
                ap50 = float(parts[3])
                metrics[class_id] = (recall, precision, ap50)
            except ValueError:
                print(f"warning: {line}")

    return metrics


def calculate_macro_micro_metrics(metrics: Dict[str, Tuple[float, float, float]],
                                  gt_counts: Dict[str, int]) -> Dict[str, float]:

    results = {}

    all_classes = list(gt_counts.keys())
    total_gt = sum(gt_counts.values())

    # Recall Precision
    recalls = []
    precisions = []
    f1_scores = []

    total_tp = 0
    total_pred = 0

    for class_id in all_classes:
        if class_id in metrics:
            recall, precision, _ = metrics[class_id]
        else:
            recall, precision = 0.0, 0.0

        recalls.append(recall)
        precisions.append(precision)

        # F1
        if precision + recall > 0:
            f1 = 2 * precision * recall / (precision + recall)
        else:
            f1 = 0.0
        f1_scores.append(f1)


        tp = recall * gt_counts[class_id]
        total_tp += tp

        if precision > 0:
            pred = tp / precision
        else:
            pred = 0
        total_pred += pred

    # Macro
    results['Macro-P'] = np.mean(precisions) if precisions else 0
    results['Macro-R'] = np.mean(recalls) if recalls else 0
    results['Macro-F1'] = np.mean(f1_scores) if f1_scores else 0

    # Micro
    if total_pred > 0:
        results['Micro-P'] = total_tp / total_pred
    else:
        results['Micro-P'] = 0

    if total_gt > 0:
        results['Micro-R'] = total_tp / total_gt
    else:
        results['Micro-R'] = 0

    if results['Micro-P'] + results['Micro-R'] > 0:
        results['Micro-F1'] = 2 * results['Micro-P'] * results['Micro-R'] / (results['Micro-P'] + results['Micro-R'])
    else:
        results['Micro-F1'] = 0

    return results


def main():

    input_text = """

Class      Recall    Precision    AP@0.5
-------  --------  -----------  --------
MTL        0.0000       0.0000    0.0000
TEE        0.0000       0.0000    0.0000
BND        0.0000       0.0000    0.0000
CRC        0.0000       0.0000    0.0000
BRN        0.0000       0.0000    0.0000
GWA        0.0000       0.0000    0.0000
SWA        0.0000       0.0000    0.0000
ESP        0.0000       0.0000    0.0000
VAL        0.0000       0.0000    0.0000
FLA        0.0000       0.0000    0.0000
CAS        0.0000       0.0000    0.0000
SLE        0.0000       0.0000    0.0000"""

    # GT
    gt_counts = {
        'MTL': 29720,
        'CRC': 573,
        'GWA': 4135,
        'SWA': 3423,
        'BND': 708,
        'SLE': 58,
        'BRN': 47,
        'TEE': 36,
        'CAS': 25,
        'VAL': 23,
        'ESP': 9,
        'FLA': 4
    }


    metrics = parse_metrics_table(input_text)

    print("data:")
    print(f"{'category':<5} {'Recall':<8} {'Precision':<10} {'AP@0.5':<8}")
    print("-" * 35)
    for class_id, (recall, precision, ap50) in metrics.items():
        print(f"{class_id:<5} {recall:<8.4f} {precision:<10.4f} {ap50:<8.4f}")
    print()


    results = calculate_macro_micro_metrics(metrics, gt_counts)


    print("result:")
    print("=" * 40)
    print(f"{'metrics':<15} {'value':<10}")
    print("-" * 40)
    for key, value in results.items():
        print(f"{key:<15} {value:.4f}")


    ap50_values = [ap50 for _, _, ap50 in metrics.values()]
    mAP = np.mean(ap50_values) if ap50_values else 0
    print(f"{'mAP@0.5':<15} {mAP:.4f}")


    print("\nstatistics:")
    print(f": {sum(gt_counts.values())}")
    print(f": {len(gt_counts)}")


    data = []
    for class_id in gt_counts.keys():
        if class_id in metrics:
            recall, precision, ap50 = metrics[class_id]
        else:
            recall, precision, ap50 = 0, 0, 0

        if precision + recall > 0:
            f1 = 2 * precision * recall / (precision + recall)
        else:
            f1 = 0

        data.append({
            'Class': class_id,
            'GT': gt_counts[class_id],
            'Recall': recall,
            'Precision': precision,
            'AP@0.5': ap50,
            'F1': f1
        })

    df = pd.DataFrame(data)
    print("\n:")
    print(df.to_string(index=False))


if __name__ == "__main__":
    main()
